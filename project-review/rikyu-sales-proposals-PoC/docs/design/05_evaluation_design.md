# 評価設計

> **関連**: [設計書サマリ](00_summary.md) | [データ設計](04_data_design.md) | [技術設計](06_technical_design.md)

---

## 6.1 評価設計の背景と考え方

### なぜ「正解データ」を定義しないのか

本PoCで扱うタスク（ニーズ推定・ソリューション推薦）には、従来の機械学習評価で用いる「唯一の正解」を定義することが本質的に困難です。

```
【具体例で考える】

入力:
  企業情報: 「製造業、売上300億、社長65歳、中計で海外展開言及、
             前期は減益、借入金増加傾向」
  面談記録: 「後継者の話題が出た、設備の老朽化を気にしていた」

AI出力:
  ニーズ1: 事業承継（社長年齢・後継者話題から）
  ニーズ2: 設備投資資金（老朽化言及から）
  ニーズ3: 海外展開支援（中計から）
  ニーズ4: 財務改善（減益・借入増から）

問題:
  → これらは全部「正解」かもしれない
  → 今のタイミングでは「事業承継」が最優先かもしれない
  → 担当者の関係性次第で「設備」から切り出すのが正解かもしれない
  → 「唯一の正解」は存在しない
```

| 困難さの種類 | 具体例 | Precision/Recallへの影響 |
|--------------|--------|-------------------------|
| **多重正解性** | 同じ企業に複数の妥当なニーズがある | 「正解セット」が定義できない |
| **順序依存性** | 「まず信頼構築→本題」が正解の場合も | 順序を考慮した指標が必要 |
| **文脈依存性** | 担当者の関係性、過去履歴で変わる | 入力に含まれない情報が影響 |
| **時間依存性** | 先月と今月で優先度が変わる | 静的な正解データが陳腐化 |
| **主観性** | ベテランAとBで推奨が違う | 評価者間で一致しない |

### 評価の基本方針

```
【従来の考え方】❌ 採用しない
  正解データ作成 → AI実行 → 正解と照合 → Precision/Recall算出

【本PoCの考え方】✅ 採用する
  AI実行 → 品質チェック → 営業知見者がレビュー → フィードバック → 改善
                ↑                ↑
          LLMによる自動化    「使える/使えない」の判断
```

**評価の目的**:
- ✅ 精度を算出し、改善する（LLM自動評価を活用し、人の評価との一致を確認）
- ✅ 「実務で使えるか」「どう改善すればよいか」を明らかにすること
- ✅ PJ出口で「何ができて、何が足りないか」を定量的に示す

---

## 6.2 開発する3つのAIと評価構造

> **MTG方針変更**: パイプラインは組みすぎないが、以下の3つのAIを開発する

```
┌─────────────────────────────────────────────────────────────────────┐
│                   3つのAIと評価の関係                                │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【AI①】顧客ニーズ推定AI                                            │
│  ├─ 入力：企業情報 + 面談記録                                       │
│  ├─ 出力：推定ニーズリスト（カテゴリ、優先度、根拠）                │
│  └─ 評価：ニーズ推定精度（人評価15件 → 自動評価AI育成）          │
│                              ↓                                      │
│  【AI②】ソリューション提案AI                                        │
│  ├─ 入力：推定ニーズ + 商材DB                                       │
│  ├─ 出力：推薦商材リスト（商材名、推薦理由）                        │
│  └─ 評価：ソリューション提案精度（2段階評価）                       │
│            ├─ 評価A: ニーズ充足度（提案が顧客ニーズを解決できるか）  │
│            └─ 評価B: ソリューション妥当性（提案理由が論理的で説得力があるか）│
│                              ↓                                      │
│  【AI③】自動評価AI（LLM-as-Judge）                                  │
│  ├─ 入力：AI①②の出力 + 正解データ                                  │
│  ├─ 出力：精度スコア + 評価理由 + 改善示唆                          │
│  └─ 評価：自動評価AI自体の精度（人の評価との一致率）                │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 評価の段階的アプローチ

**課題認識**: 自動評価AIの精度が低い段階では、その評価結果でニーズ推定AI・ソリューション提案AIの精度を正確に測定できない

```
┌─────────────────────────────────────────────────────────────────────┐
│                    評価の段階的アプローチ                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【Phase 1】人が代表15件を評価                                    │
│  ├─ 目的：ニーズ推定AI・ソリューション提案AIの精度を正確に測定       │
│  ├─ 内容：多様性を確保した代表シナリオを人が評価                     │
│  └─ 成果：正確な精度測定 + 課題分析 + 自動評価AI用の教師データ       │
│                              ↓                                      │
│  【Phase 2】人の評価データで自動評価AIを育成                         │
│  ├─ 目的：自動評価AIの精度向上（人との一致率80%目標）                │
│  ├─ 内容：Phase 1の評価データを教師データとして活用                  │
│  └─ 成果：自動評価AIの精度検証                                       │
│                              ↓                                      │
│  【Phase 3】自動評価AI + 人がスポット確認                            │
│  ├─ 目的：残り85件の評価、継続的な精度監視                        │
│  ├─ 内容：自動評価AIが一定精度に達したら残りを評価                   │
│  └─ 成果：100件全体の精度把握、改善効果の測定                        │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 各AIの精度測定

| AI | 精度指標 | 測定方法 | 目標値 |
|----|----------|----------|--------|
| **AI① ニーズ推定** | ニーズ抽出精度 | 正解ニーズとの一致率（人評価15件） | 70%以上 |
| **AI② ソリューション提案** | ニーズ充足度 | 提案が顧客ニーズを解決できる率（人評価） | 70%以上 |
| **AI② ソリューション提案** | ソリューション妥当性 | 提案理由が論理的で説得力がある率（人評価） | 70%以上 |
| **AI③ 自動評価** | 人との一致率 | 自動評価と人評価の一致率（15件） | 80%以上 |

---

## 6.3 評価基準（ルーブリック）【仮版】

> **注**: 本ルーブリックはPoC開始時の仮版です。Phase 1の人評価を通じて精緻化していきます。

### 5段階評価と◯△×判定の対応

| 5段階 | ◯△× | 意味 | 精度計算での扱い |
|-------|------|------|------------------|
| 5, 4 | ◯ | 実用レベル（そのまま使える/軽微な修正で使える） | 合格 |
| 3 | △ | 条件付き（修正すれば使える） | 条件付き合格 |
| 2, 1 | × | 不合格（使えない） | 不合格 |

**精度目標**: ◯率70%以上 = 15件中11件以上が◯

### AI① ニーズ推定AI 評価基準

| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 明示的ニーズ・潜在ニーズを漏れなく抽出、優先度付けも適切 |
| 4 | ◯ | 良好 | 主要なニーズを正確に抽出、軽微な漏れ/優先度ズレは許容範囲 |
| 3 | △ | 条件付き | 核心的ニーズは抽出できているが、一部漏れや誤解があり補足が必要 |
| 2 | × | 要改善 | ニーズ抽出が不十分、重要なニーズの見落としがある |
| 1 | × | 不合格 | ニーズを正しく理解できていない、的外れな抽出 |

**評価観点**:
- ニーズの網羅性（明示・潜在両方）
- ニーズの正確性（顧客の意図との一致）
- 優先度の妥当性

**◯△×判定の具体例**:
| 判定 | 具体例 |
|------|--------|
| ◯ | 「資金調達」「事業拡大」「後継者問題」の3ニーズを正確に抽出 |
| △ | 主要ニーズは抽出したが「海外展開意向」という潜在ニーズを見落とし |
| × | 「資金繰り改善」と言われて「コスト削減」と誤解、的外れな方向 |

### AI② ソリューション提案AI 評価基準

**ニーズ充足度**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 全てのニーズに対して適切なソリューションを提案 |
| 4 | ◯ | 良好 | 主要ニーズを満たすソリューションを提案、軽微な不足は許容 |
| 3 | △ | 条件付き | 核心的ニーズには対応、一部ニーズが未対応だが補足可能 |
| 2 | × | 要改善 | 重要なニーズへの対応が不十分 |
| 1 | × | 不合格 | ニーズとソリューションが合致していない |

**◯△×判定の具体例（ニーズ充足度）**:
| 判定 | 具体例 |
|------|--------|
| ◯ | 「資金調達ニーズ」に対し融資・社債・増資の選択肢を適切に提示 |
| △ | 融資は提案したが、規模に適した社債オプションの提示が漏れ |
| × | 「M&Aニーズ」に対し全く関係ない「為替ヘッジ」を提案 |

**ソリューション妥当性**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 提案理由が明確で説得力があり、実現可能性も高い |
| 4 | ◯ | 良好 | 論理的な提案で実現可能、一部補足説明があればより良い |
| 3 | △ | 条件付き | 提案の方向性は妥当だが、理由の説明が不十分で補足が必要 |
| 2 | × | 要改善 | 提案の根拠が弱い、または実現性に疑問がある |
| 1 | × | 不合格 | 提案が論理的でない、または実現不可能 |

**◯△×判定の具体例（ソリューション妥当性）**:
| 判定 | 具体例 |
|------|--------|
| ◯ | 「同業界の類似規模企業Aでも成約実績あり、財務状況から実現可能」と具体的根拠 |
| △ | 「融資が適切」と結論は正しいが「なぜ融資か」の説明が抽象的 |
| × | 「M&Aを推奨」としながら、なぜM&Aが最適かの理由が欠如 |

**評価観点**:
- ニーズとの整合性
- 提案理由の論理性・説得力
- 実現可能性（顧客状況を考慮）
- 過去事例との整合性

### AI③ 自動評価AI 精度検証基準

**一致率の計算方法**:
```
一致率 = (人と自動評価AIが同じ◯△×判定をした件数) / 全件数
```

**目標**: 一致率80%以上（15件中12件以上が一致）

**判定基準**:
| 一致率 | 判定 | Phase 3への適用 |
|--------|------|-----------------|
| 80%以上 | 信頼可能 | 自動評価のみで可 |
| 60-79% | 条件付き | 自動評価 + 人がスポット確認 |
| 60%未満 | 要改善 | 自動評価AI のプロンプト改善が必要 |

---

## 6.4 評価の3層構造

評価を3つの層に分け、それぞれの役割を明確化します。

```
┌─────────────────────────────────────────────────────────────────────┐
│                        評価の3層構造                                 │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Layer 1: LLM自動品質チェック（毎回・全件・工数ゼロ）                 │
│  ─────────────────────────────────────────────────                  │
│  ・ハルシネーション検出（存在しない商材名など）                      │
│  ・論理整合性チェック（根拠と結論の矛盾）                            │
│  ・業界整合性チェック（IT企業に農業機械など）                        │
│  → 「明らかにダメ」を自動排除                                       │
│                              ↓                                      │
│  Layer 2: LLM比較評価（毎日〜週2-3回・工数極小）                     │
│  ─────────────────────────────────────────────                      │
│  ・ベースライン vs 改善版の相対比較                                  │
│  ・「AとBどちらがマシか」の判定                                      │
│  → 改善方向の確認を高速化                                           │
│                              ↓                                      │
│  Layer 3: 営業知見者実用性評価（週次・絞り込み済みのみ）                    │
│  ─────────────────────────────────────────────                      │
│  ・「使える/使えない」の最終判断                                     │
│  ・具体的な改善フィードバック                                        │
│  → 実務観点での品質保証                                             │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**なぜ3層なのか**:
- Layer 1だけでは「使えるか」の判断ができない
- Layer 3だけでは営業知見者の負荷が大きすぎる（全件は見れない）
- Layer 2を挟むことで、改善サイクルを高速に回せる

---

## 6.5 Layer 1: 自動品質チェック（LLM-as-Judge）

| 項目 | 内容 |
|------|------|
| **目的** | 「明らかにダメな出力」を自動で検出・フィルタリング |
| **タイミング** | 開発中、常時（全件自動実行） |
| **判定者** | LLM（GPT-5.2） + カスタムルーブリック |
| **トレース** | Opik（抽象化レイヤー経由、LangFuse等への切り替え可能） |
| **工数** | ゼロ（完全自動化） |

### チェック項目と判定ロジック

| # | チェック項目 | 判定方法 | NG例 |
|---|-------------|----------|------|
| C1 | **ハルシネーション** | 出力された商材名が商材マスタに存在するか | 「りそなビジネスローンプレミアム」（存在しない） |
| C2 | **論理整合性** | 根拠からそのニーズが導けるか（LLM判定） | 根拠「売上好調」→ニーズ「資金繰り改善」 |
| C3 | **業界整合性** | その業界の企業に妥当なニーズ/商材か | IT企業に「農業機械リース」を推薦 |
| C4 | **情報カバレッジ** | 入力の重要情報をAIが拾えているか | 「社長70歳」があるのに事業承継に言及なし |

### 評価指標

| 指標 | 定義 | 目標値 | 設定根拠 |
|------|------|--------|----------|
| **自動チェック通過率** | Layer1を全てpassした出力の割合 | **90%以上** | 10件に1件以上NGが出ると改善が追いつかない |
| **ハルシネーション率** | 存在しない商品名等を出力した割合 | **5%以下** | 実務利用において致命的なエラーのため厳格に |
| **論理矛盾率** | 根拠と結論が矛盾している割合 | **10%以下** | 信頼性に直結するため |
| **マッチ率** | 正解商品と提案商品の一致率 | **60%以上** | 改善サイクルの効果確認用 |
| **ナレッジ投入効果** | ナレッジ投入前後での精度差分 | **+15%** | ナレッジの価値を定量化 |

### カスタムルーブリック定義

Layer 1の自動評価では、ドメイン特化の**カスタムルーブリック**を定義し、LLM-as-Judgeで評価を実行する。

#### ルーブリック一覧

| ルーブリック名 | 適用対象 | 評価観点 |
|---------------|---------|---------|
| **needs_coverage** | AI① ニーズ推定 | ニーズの網羅性（顕在・潜在両方） |
| **evidence_quality** | AI① ニーズ推定 | 根拠の妥当性・論理性 |
| **practicality** | AI① AI② 両方 | 実用性・具体性 |
| **solution_fit** | AI② ソリューション提案 | ニーズとソリューションの適合度 |
| **reasoning_clarity** | AI② ソリューション提案 | 提案理由の明確さ・説得力 |

#### ルーブリック詳細定義

```python
# === カスタムルーブリック定義 ===
CUSTOM_RUBRICS = {
    "needs_coverage": {
        "name": "ニーズ網羅性",
        "description": "顧客の顕在ニーズ・潜在ニーズをどれだけ網羅的に抽出できているか",
        "criteria": """
        5: 顕在ニーズを全て抽出し、潜在ニーズも的確に推定できている
        4: 主要な顕在・潜在ニーズを抽出できているが、軽微な抜けがある
        3: 顕在ニーズの半数程度を抽出、潜在ニーズは一部のみ
        2: 重要な顕在ニーズに抜け漏れがある
        1: ニーズをほとんど抽出できていない、または的外れ
        """,
        "examples": {
            5: "資金調達、事業承継、海外展開、設備投資の4つのニーズを全て抽出し、"
               "社長の年齢から潜在的な相続対策ニーズも推定",
            3: "資金調達と設備投資は抽出したが、面談記録にあった事業承継の話題を見落とし",
            1: "「業績改善」という漠然としたニーズのみで、具体的なニーズを抽出できていない"
        }
    },
    "evidence_quality": {
        "name": "根拠の妥当性",
        "description": "ニーズ推定の根拠が入力情報から論理的に導出されているか",
        "criteria": """
        5: 全てのニーズに具体的な根拠があり、入力情報から論理的に導出されている
        4: 主要なニーズに妥当な根拠があるが、一部推測に依存している
        3: 根拠はあるが、入力情報との紐付けが曖昧な部分がある
        2: 根拠が不十分、または論理の飛躍がある
        1: 根拠が示されていない、または入力情報と矛盾している
        """,
        "examples": {
            5: "「社長65歳、後継者の話題が出た」→ 事業承継ニーズと明確に紐付け",
            3: "「事業承継ニーズあり」とだけ記載し、どの情報から導いたか不明確",
            1: "「資金繰りが厳しい」という根拠から「海外展開ニーズ」を導出（論理の飛躍）"
        }
    },
    "practicality": {
        "name": "実用性・具体性",
        "description": "出力が営業担当者の提案準備として実際に使えるレベルか",
        "criteria": """
        5: そのまま提案準備の起点として使える具体性と実用性がある
        4: 軽微な補足・修正で提案準備に使える
        3: 参考程度にはなるが、そのままでは使えない（追加調査必要）
        2: 抽象的すぎて提案準備には使えない
        1: 的外れで全く使えない
        """,
        "examples": {
            5: "ニーズごとに優先度、根拠、次のアクションまで記載",
            3: "ニーズは列挙されているが、優先度や具体的なアクションが不明",
            1: "「顧客のニーズを深掘りしましょう」という一般論のみ"
        }
    },
    "solution_fit": {
        "name": "ソリューション適合度",
        "description": "推定ニーズに対して適切なソリューションが提案されているか",
        "criteria": """
        5: 全てのニーズに対して最適なソリューションが提案されている
        4: 主要ニーズに適切なソリューションが提案されているが、一部改善の余地あり
        3: ニーズとソリューションの対応は概ね正しいが、一部不整合がある
        2: ニーズとソリューションの対応が不十分
        1: ニーズと無関係なソリューションが提案されている
        """,
        "examples": {
            5: "資金調達ニーズに対し、企業規模・財務状況を踏まえた融資/社債/増資の選択肢を提示",
            3: "資金調達ニーズに融資を提案したが、企業規模に適した社債オプションが漏れ",
            1: "M&Aニーズに対して為替ヘッジ商品を提案（全く的外れ）"
        }
    },
    "reasoning_clarity": {
        "name": "提案理由の明確さ",
        "description": "なぜそのソリューションを推薦するのか、理由が明確に説明されているか",
        "criteria": """
        5: 提案理由が論理的かつ具体的で、顧客を説得できるレベル
        4: 提案理由は明確だが、一部補足があるとより説得力が増す
        3: 提案理由はあるが、抽象的または根拠が弱い
        2: 提案理由が不十分または不明確
        1: 提案理由が示されていない、または矛盾している
        """,
        "examples": {
            5: "「同業界の類似規模企業Aで成約実績あり、財務状況から実現可能」と具体的根拠を提示",
            3: "「融資が適切です」と結論のみで、なぜ融資が最適かの説明なし",
            1: "「M&Aを推奨」としながら、理由が全く記載されていない"
        }
    }
}
```

#### ルーブリック評価の実装

```python
# === ルーブリック評価実装 ===
from typing import Dict, Any
from pydantic import BaseModel, Field

class RubricScore(BaseModel):
    """個別ルーブリックの評価結果"""
    score: int = Field(ge=1, le=5, description="スコア（1-5）")
    rating: str = Field(description="◯/△/× の判定")
    comment: str = Field(description="評価コメント")
    evidence: str = Field(description="スコアの根拠となる出力部分")

class EvaluationResult(BaseModel):
    """評価結果全体"""
    scores: Dict[str, RubricScore] = Field(description="各ルーブリックのスコア")
    overall_rating: str = Field(description="総合評価 ◯/△/×")
    overall_comment: str = Field(description="総合コメント")


class RubricEvaluator:
    """カスタムルーブリックによる評価"""

    def __init__(self, client: "AzureOpenAIClient", tracer: "TracerInterface"):
        self.client = client
        self.tracer = tracer
        self.rubrics = CUSTOM_RUBRICS

    async def evaluate(
        self,
        output_type: str,  # "needs" or "solution"
        output: dict,
        input_context: dict
    ) -> EvaluationResult:
        """出力をルーブリックに基づいて評価"""

        # 出力タイプに応じたルーブリックを選択
        applicable_rubrics = self._get_applicable_rubrics(output_type)

        with self.tracer.span("rubric_evaluation") as span:
            span.set_input({"output_type": output_type, "rubrics": list(applicable_rubrics.keys())})

            scores = {}
            for rubric_key, rubric in applicable_rubrics.items():
                score = await self._evaluate_single_rubric(
                    rubric_key, rubric, output, input_context
                )
                scores[rubric_key] = score

                # Tracerに評価結果を記録
                self.tracer.log_evaluation(
                    score=score.score / 5.0,  # 0-1に正規化
                    rubric_name=rubric_key,
                    rating=score.rating,
                    metadata={"comment": score.comment}
                )

            # 総合評価を算出
            overall = self._calculate_overall(scores)

            span.set_output({
                "scores": {k: v.model_dump() for k, v in scores.items()},
                "overall_rating": overall["rating"]
            })

            return EvaluationResult(
                scores=scores,
                overall_rating=overall["rating"],
                overall_comment=overall["comment"]
            )

    async def _evaluate_single_rubric(
        self,
        rubric_key: str,
        rubric: dict,
        output: dict,
        input_context: dict
    ) -> RubricScore:
        """単一ルーブリックでの評価"""

        system_prompt = f"""あなたは{rubric['name']}を評価する評価者です。

以下の評価基準に基づいて、出力を1-5のスコアで評価してください。

【評価基準】
{rubric['criteria']}

【評価例】
スコア5の例: {rubric['examples'][5]}
スコア3の例: {rubric['examples'][3]}
スコア1の例: {rubric['examples'][1]}

必ず以下の形式で回答してください:
- score: 1-5の整数
- rating: ◯（4-5）、△（3）、×（1-2）
- comment: 評価理由（50字以内）
- evidence: スコアの根拠となる出力部分を引用
"""

        user_prompt = f"""【入力コンテキスト】
{input_context}

【評価対象の出力】
{output}

上記の出力を「{rubric['name']}」の観点で評価してください。"""

        result = self.client.structured_output(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_model=RubricScore
        )

        return result

    def _get_applicable_rubrics(self, output_type: str) -> Dict[str, dict]:
        """出力タイプに応じたルーブリックを取得"""
        if output_type == "needs":
            return {
                k: v for k, v in self.rubrics.items()
                if k in ["needs_coverage", "evidence_quality", "practicality"]
            }
        elif output_type == "solution":
            return {
                k: v for k, v in self.rubrics.items()
                if k in ["solution_fit", "reasoning_clarity", "practicality"]
            }
        else:
            raise ValueError(f"Unknown output type: {output_type}")

    def _calculate_overall(self, scores: Dict[str, RubricScore]) -> dict:
        """総合評価を算出"""
        avg_score = sum(s.score for s in scores.values()) / len(scores)

        if avg_score >= 4.0:
            rating = "◯"
            comment = "実用レベル：提案準備の起点として使用可能"
        elif avg_score >= 3.0:
            rating = "△"
            comment = "条件付き：補足・修正が必要だが参考になる"
        else:
            rating = "×"
            comment = "要改善：そのままでは使用不可"

        return {"rating": rating, "comment": comment}
```

#### トレースツールとの連携

評価結果は **Opik**（抽象化レイヤー経由）に自動記録され、以下の分析が可能:

```
┌─────────────────────────────────────────────────────────────────────┐
│                  Opikダッシュボードでの可視化                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【評価スコア推移】                                                 │
│  ├─ ルーブリック別のスコア推移（時系列）                           │
│  ├─ 改善前後のスコア比較                                           │
│  └─ プロンプトバージョン別の精度比較                               │
│                                                                     │
│  【弱点分析】                                                       │
│  ├─ スコアが低いルーブリックの特定                                 │
│  ├─ ×判定が多いケースの傾向分析                                    │
│  └─ 改善提案の自動生成（低評価時）                                 │
│                                                                     │
│  【ツール切り替え】                                                 │
│  ├─ 環境変数 TRACER_TYPE=opik | langfuse | noop で切り替え         │
│  ├─ 抽象化レイヤーにより、コード変更なしで移行可能                 │
│  └─ テスト時は NoopTracer で高速実行                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 6.6 Layer 2: LLM比較評価（Pairwise Comparison）

| 項目 | 内容 |
|------|------|
| **目的** | 改善の方向性を素早く確認（絶対評価より相対評価が容易） |
| **タイミング** | 改善サイクル毎（**毎日〜週2-3回**可能） |
| **判定者** | LLM（GPT-5.2） |
| **工数** | 極めて低（完全自動化、結果確認のみ） |

**なぜ相対評価か**:
- 「この出力は80点」という絶対評価は難しい
- 「AとBどちらがマシか」の相対評価は判断しやすい
- 改善の方向性が正しいかを素早く確認できる

### 評価指標

| 指標 | 定義 | 用途 |
|------|------|------|
| **勝率** | 改善版が勝った割合（50件中何件勝ったか） | 改善効果の確認 |
| **観点別勝率** | 網羅性/優先度/根拠別の勝率 | 弱点の特定 |
| **理由の傾向** | LLMが挙げた理由のパターン分析 | 次の改善方針決定 |

### LLM-as-Judgeの限界

```
⚠️ LLM-as-Judgeの限界

1. LLM自身のバイアス
   - 自分（同じLLM）の出力を好む傾向がある
   - 長い出力を「より詳細で良い」と評価しがち

2. ドメイン知識の限界
   - 銀行業界特有の暗黙知は判断できない
   - 「この業界ではこの商材は売れない」等の現場感覚

3. 位置付けの明確化
   - Layer 2は「傾向の把握」「改善方向の確認」用
   - 最終判断はLayer 3の営業知見者評価で行う
```

---

## 6.7 Layer 3: 営業知見者実用性評価

| 項目 | 内容 |
|------|------|
| **目的** | 「実務で使えるか」の最終判断、改善のための具体的フィードバック |
| **タイミング** | 週次レビュー会（毎週60分）または隔週 |
| **判定者** | 営業知見者（ソリビ担当者）2-3名 |
| **工数** | 営業知見者: 週1時間 + 事前確認30分（**Layer 1/2で絞り込み済みのため軽量**） |

### 営業知見者評価シート

```
Q1. この出力を提案準備の起点として使えますか？
    [ ] 5: そのまま使える
    [ ] 4: 少し修正すれば使える
    [ ] 3: 参考程度にはなる
    [ ] 2: あまり役に立たない
    [ ] 1: 全く使えない

Q2. 抜けている重要なニーズは？（自由記述）
Q3. 的外れなニーズは？（自由記述）
Q4. こう直せば使える、というポイントは？（自由記述）
```

### 評価指標

| 指標 | 定義 | 目標値 | 設定根拠 |
|------|------|--------|----------|
| **実用性スコア** | Q1の平均値（1-5点） | **3.5以上** | 「参考になる」と「少し修正すれば使える」の中間 |
| **そのまま使える率** | Q1で4-5の割合 | **50%以上** | 半数以上がそのまま or 少修正で使えるレベル |
| **参考になる率** | Q1で3以上の割合 | **80%以上** | 大多数が最低限「参考にはなる」レベル |
| **重大な抜け漏れ率** | Q2で重要な抜けを指摘された割合 | **20%以下** | 5件に1件以上の重大な抜けは許容できない |

---

## 6.8 評価指標サマリ

| Layer | 指標 | 目標値 | 測定タイミング | 設定根拠 |
|-------|------|--------|---------------|----------|
| **L1** | 自動チェック通過率 | 90%以上 | 毎回 | 改善サイクルを回すための最低ライン |
| **L1** | ハルシネーション率 | 5%以下 | 毎回 | 実務利用で致命的なエラー |
| **L1** | 論理矛盾率 | 10%以下 | 毎回 | 信頼性に直結 |
| **L2** | 改善版勝率 | 60%以上 | 改善サイクル毎 | 改善が正しい方向か確認 |
| **L3** | 実用性スコア | 3.5以上 | 週次 | 「参考になる」以上が平均 |
| **L3** | そのまま使える率 | 50%以上 | 週次 | 半数が直接活用可能 |
| **L3** | 参考になる率 | 80%以上 | 週次 | 大多数が最低限有用 |
| **L3** | 重大な抜け漏れ率 | 20%以下 | 週次 | 5件に1件以上は許容できない |
