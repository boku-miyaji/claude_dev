# 評価設計

> **関連**: [設計書サマリ](00_summary.md) | [データ設計](04_data_design.md) | [技術設計](06_technical_design.md) | [ナレッジ設計](14_knowledge_design.md)

---

## 6.1 評価設計の背景と考え方

### なぜ「正解データ」を定義しないのか

本PoCで扱うタスク（ニーズ推定・ソリューション推薦）には、従来の機械学習評価で用いる「唯一の正解」を定義することが本質的に困難です。

```
【具体例で考える】

入力:
  企業情報: 「製造業、売上300億、社長65歳、中計で海外展開言及、
             前期は減益、借入金増加傾向」
  面談記録: 「後継者の話題が出た、設備の老朽化を気にしていた」

AI出力:
  ニーズ1: 事業承継（社長年齢・後継者話題から）
  ニーズ2: 設備投資資金（老朽化言及から）
  ニーズ3: 海外展開支援（中計から）
  ニーズ4: 財務改善（減益・借入増から）

問題:
  → これらは全部「正解」かもしれない
  → 今のタイミングでは「事業承継」が最優先かもしれない
  → 担当者の関係性次第で「設備」から切り出すのが正解かもしれない
  → 「唯一の正解」は存在しない
```

| 困難さの種類 | 具体例 | Precision/Recallへの影響 |
|--------------|--------|-------------------------|
| **多重正解性** | 同じ企業に複数の妥当なニーズがある | 「正解セット」が定義できない |
| **順序依存性** | 「まず信頼構築→本題」が正解の場合も | 順序を考慮した指標が必要 |
| **文脈依存性** | 担当者の関係性、過去履歴で変わる | 入力に含まれない情報が影響 |
| **時間依存性** | 先月と今月で優先度が変わる | 静的な正解データが陳腐化 |
| **主観性** | ベテランAとBで推奨が違う | 評価者間で一致しない |

### 評価の基本方針

```
【従来の考え方】❌ 採用しない
  正解データ作成 → AI実行 → 正解と照合 → Precision/Recall算出

【本PoCの考え方】✅ 採用する
  AI実行 → 品質チェック → 営業知見者がレビュー → フィードバック → 改善
                ↑                ↑
          LLMによる自動化    「使える/使えない」の判断
```

**評価の目的**:
- ✅ 精度を算出し、改善する（LLM自動評価を活用し、人の評価との一致を確認）
- ✅ 「実務で使えるか」「どう改善すればよいか」を明らかにすること
- ✅ PJ出口で「何ができて、何が足りないか」を定量的に示す

---

## 6.2 開発する6つのAIと3層アーキテクチャ

> **設計方針**:
> - **生成レイヤー**: ニーズ推定・提案方針策定（根拠必須）
> - **評価レイヤー**: 品質評価（根拠必須、解像度はルーブリックの一つ）
> - **改善レイヤー**: 課題特定・改善策提案（評価が低い場合に発動）
>
> **重要**: AI②は「商品起点」ではなく「ニーズ・経営アジェンダ起点」の提案方針を策定

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           6AIアーキテクチャ（3層構造）                           │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  【生成レイヤー】                                                                │
│  ┌─────────────────────┐         ┌─────────────────────┐                       │
│  │ AI① ニーズ推定AI    │────────▶│ AI② 提案方針策定AI  │                       │
│  │ ※根拠必須           │         │ ※根拠必須           │                       │
│  └──────────┬──────────┘         └──────────┬──────────┘                       │
│             │                               │                                   │
│             ▼                               ▼                                   │
│  【評価レイヤー】                                                                │
│  ┌─────────────────────┐         ┌─────────────────────┐                       │
│  │ AI③ ニーズ推定評価AI│         │ AI④ 提案方針評価AI  │                       │
│  │ ※根拠必須           │         │ ※根拠必須           │                       │
│  │ ※解像度はルーブリック│         │ ※解像度・充足度は   │                       │
│  │   の一つ            │         │   ルーブリックの一つ │                       │
│  └──────────┬──────────┘         └──────────┬──────────┘                       │
│             │                               │                                   │
│             ▼ (評価が△×の場合)              ▼ (評価が△×の場合)                  │
│  【改善レイヤー】                                                                │
│  ┌─────────────────────┐         ┌─────────────────────┐                       │
│  │ AI⑤ ニーズ推定      │         │ AI⑥ 提案方針        │                       │
│  │   課題特定・改善策AI │         │   課題特定・改善策AI │                       │
│  └─────────────────────┘         └─────────────────────┘                       │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 6.2.1 生成レイヤー

#### 【AI①】ニーズ推定AI

| 項目 | 内容 |
|------|------|
| **役割** | 入力情報から顧客のニーズを推定し、**なぜそう判断したかを明示** |

**入力:**
```yaml
企業情報:
  - 財務データ（売上、利益率、借入依存度等）
  - 業種・規模
  - 経営者情報
面談記録:
  - ヒアリング内容
  - 顧客発言
経営アジェンダシート:
  - 経営課題・優先事項
キーパーソンマップ:
  - 意思決定者・影響者
```

**出力:**
```yaml
推定ニーズ:
  - id: N1
    ニーズ: 物流コスト削減
    優先度: 高
    根拠: |
      【なぜこのニーズがあると判断したか】
      1. 面談記録で社長が「物流費が経営を圧迫」と明言（直接的証拠）
      2. 財務データで販管費率が業界平均+5%（定量的裏付け）
      3. 経営アジェンダに「コスト構造改革」が最優先事項（優先度の根拠）

  - id: N2
    ニーズ: 事業承継対策
    優先度: 中
    根拠: |
      【なぜこのニーズがあると判断したか】
      1. 社長65歳、後継者情報なし（潜在的リスク）
      2. 面談で「10年後を考えている」と発言（示唆的証拠）
      ※明示的な要望はないが、潜在ニーズとして推定

情報充足度: 中
  不足情報:
    - 物流の詳細内訳（自社配送 vs 外注比率）
    - 後継者候補の有無
```

#### 【AI②】提案方針策定AI

| 項目 | 内容 |
|------|------|
| **役割** | **ニーズ・経営アジェンダ起点**で提案方針を策定（商品起点ではない） |
| **重要** | 単一商品の推薦ではなく、複数商材を組み合わせた戦略的アプローチ |

**入力:**
```yaml
AI①出力:
  - 推定ニーズ（根拠付き）
企業情報:
  - 財務データ、経営者情報
商材情報:
  - 利用可能な商材・サービス一覧
経営アジェンダ:
  - 顧客の経営課題・優先事項
```

**出力:**
```yaml
提案方針:
  テーマ: 「コスト構造改革と事業継続性の両立」

  アプローチ:
    根拠: |
      【なぜこの方針なのか】
      1. 経営アジェンダの最優先が「コスト構造改革」→ここを入口に
      2. 社長の年齢・後継者不在から事業継続リスクあり→中長期視点で提案
      3. 両課題は相互に関連（コスト改善→企業価値向上→承継選択肢拡大）

  ストーリー:
    - Phase 1: 物流効率化で短期成果を出し、信頼構築
    - Phase 2: コスト削減の成果を基に、中期経営計画策定を支援
    - Phase 3: 事業承継の選択肢（後継者育成 or M&A）を提示

  活用商材（組み合わせ）:
    Phase 1:
      - 物流効率化コンサルティング
      - 業務改善ツール導入支援
    Phase 2:
      - 中期経営計画策定支援
    Phase 3:
      - 事業承継コンサルティング

  根拠: |
    【なぜこの商材組み合わせなのか】
    - 単発の商材提案ではなく、経営アジェンダに沿った段階的アプローチ
    - Phase 1で成果を出し関係構築→Phase 2-3で本丸の課題に踏み込む

ネクストアクション:
  - 物流現状診断（簡易版）を提案し、Phase 1の入口を作る
  - 次回面談で中期的な経営課題についてヒアリング
```

### 6.2.2 評価レイヤー

#### 【AI③】ニーズ推定評価AI（LLM-as-Judge）

| 項目 | 内容 |
|------|------|
| **役割** | ニーズ推定の品質を評価（解像度はルーブリックの一つ） |

**入力:**
```yaml
AI①入力:
  - 企業情報、面談記録、経営アジェンダ、キーパーソンマップ
AI①出力:
  - 推定ニーズ（根拠付き）
評価ルーブリック:
  - needs_coverage（網羅性）
  - evidence_quality（根拠の質）
  - resolution（解像度）※問題/状況の把握度
  - practicality（実用性）
```

**出力:**
```yaml
評価結果:
  総合評価: △（スコア: 3.5/5）

  ルーブリック別評価:
    needs_coverage（網羅性）:
      スコア: 3
      判定: △
      評価理由: |
        【根拠】
        - 顕在ニーズ（物流コスト）は正しく特定 ✓
        - 潜在ニーズ（事業承継）も適切に推定 ✓
        - 見落とし: 面談記録に「業務のIT化を検討」とあるがニーズに含まれていない

    evidence_quality（根拠の質）:
      スコア: 4
      判定: ◯
      評価理由: |
        【根拠】
        - 各ニーズに複数の証拠（発言+データ）を引用 ✓
        - 定量的裏付け（販管費率+5%）が含まれている ✓

    resolution（解像度）:
      スコア: 3
      判定: △
      評価理由: |
        【根拠】
        - 問題の解像度: 中（「物流コストが高い」は分かるが内訳・原因が不明）
        - 状況の解像度: 高（企業の基本情報は十分）
        - 不足: 物流コストの詳細内訳、目標値

    practicality（実用性）:
      スコア: 4
      判定: ◯
      評価理由: |
        【根拠】
        - ニーズの記述が具体的で営業が活用しやすい ✓
        - 優先度付けが明確 ✓
```

#### 【AI④】提案方針評価AI（LLM-as-Judge）

| 項目 | 内容 |
|------|------|
| **役割** | 提案方針の品質を評価（解像度・ニーズ充足度はルーブリックの一つ） |

**入力:**
```yaml
AI①出力:
  - 推定ニーズ（根拠付き）
AI②入力:
  - 商材情報、経営アジェンダ
AI②出力:
  - 提案方針（根拠付き）
評価ルーブリック:
  - strategy_coherence（方針の一貫性）
  - needs_fulfillment（ニーズ充足度）
  - resolution（解像度）※ゴール/制約の把握度
  - actionability（実行可能性）
```

**出力:**
```yaml
評価結果:
  総合評価: ◯（スコア: 4.0/5）

  ルーブリック別評価:
    strategy_coherence（方針の一貫性）:
      スコア: 5
      判定: ◯
      評価理由: |
        【根拠】
        - 経営アジェンダ「コスト構造改革」を起点にした一貫したストーリー ✓
        - Phase 1→2→3の流れが論理的 ✓
        - 商品ありきではなく顧客課題起点 ✓

    needs_fulfillment（ニーズ充足度）:
      スコア: 4
      判定: ◯
      評価理由: |
        【根拠】
        - N1（物流コスト削減）: Phase 1で直接対応 ✓
        - N2（事業承継）: Phase 3で対応 ✓
        - 減点: IT化ニーズ（見落とし）への対応がない

    resolution（解像度）:
      スコア: 3
      判定: △
      評価理由: |
        【根拠】
        - ゴールの解像度: 低（コスト削減の目標値・期限が不明のまま提案）
        - 制約の解像度: 低（予算・意思決定プロセスが不明）

    actionability（実行可能性）:
      スコア: 4
      判定: ◯
      評価理由: |
        【根拠】
        - ネクストアクションが具体的 ✓
        - 「物流現状診断」という入口提案は実行しやすい ✓
```

### 6.2.3 改善レイヤー

> **発動条件**: 評価レイヤー（AI③④）の総合評価が△または×の場合

#### 【AI⑤】ニーズ推定 課題特定・改善策AI

| 項目 | 内容 |
|------|------|
| **役割** | ニーズ推定の問題点を特定し、具体的な改善策を提案 |
| **発動条件** | AI③の総合評価が△または×の場合 |

**入力:**
```yaml
AI①入力:
  - 企業情報、面談記録等
AI①出力:
  - 推定ニーズ（根拠付き）
AI③評価結果:
  - ルーブリック別評価、評価理由
```

**出力:**
```yaml
課題特定:
  - id: ISS-001
    課題: ニーズの見落とし（IT化ニーズ）
    深刻度: 中
    原因分析: |
      面談記録の「業務のIT化を検討」という発言を
      ニーズとして抽出するロジックが不足している。
      おそらく「検討」という曖昧な表現のため、
      確定ニーズとして認識されなかった。

改善策:
  AI改善:
    - 「検討中」「考えている」等の表現も潜在ニーズとして抽出するよう
      プロンプトを修正
    - 抽出したニーズを「顕在」「潜在」に分類して出力

  運用改善:
    - 営業担当へのフィードバック: 次回ヒアリングで詳細確認
    - 入力フォーマットに「詳細ヒアリング項目」チェックリストを追加

優先度付き改善アクション:
  1. [高] プロンプト修正（潜在ニーズ抽出強化）
  2. [中] 出力フォーマット改善（顕在/潜在の分類）
  3. [低] 入力フォーマットの改善提案
```

#### 【AI⑥】提案方針 課題特定・改善策AI

| 項目 | 内容 |
|------|------|
| **役割** | 提案方針の問題点を特定し、具体的な改善策を提案 |
| **発動条件** | AI④の総合評価が△または×の場合 |

**入力:**
```yaml
AI②入力:
  - AI①出力、商材情報、経営アジェンダ
AI②出力:
  - 提案方針（根拠付き）
AI④評価結果:
  - ルーブリック別評価、評価理由
```

**出力:**
```yaml
課題特定:
  - id: ISS-101
    課題: 見落としニーズへの対応がない（IT化）
    深刻度: 中
    原因分析: |
      AI①でIT化ニーズが見落とされたため、
      AI②の提案方針にも反映されていない。
      これは上流（AI①）の問題が伝播したケース。

  - id: ISS-102
    課題: 解像度が低いまま提案方針を策定
    深刻度: 中
    原因分析: |
      ゴール（コスト削減目標）・制約（予算）が不明のまま
      具体的な商材組み合わせを提案している。

改善策:
  AI改善:
    - AI①の改善を優先（上流の問題）
    - 解像度に応じた出力粒度の調整
      低解像度: 大まかな方向性のみ
      中解像度: 商材カテゴリレベル
      高解像度: 具体的商材と組み合わせ

  運用改善:
    - 解像度が「低」の場合は具体提案を控え、
      まず情報収集フェーズを提案するフローに変更

優先度付き改善アクション:
  1. [高] AI①の改善（上流問題の解消）
  2. [高] 解像度に応じた出力粒度調整
  3. [中] 解像度向上のためのヒアリング項目の自動生成
```

### 6.2.4 フェーズ別実装計画

#### Phase 1: シンプル版（W2-3）

```
【実装範囲】
├─ AI①②: 基本実装（根拠出力を必須化）
├─ AI③④: 基本実装（評価理由=根拠を必須化、解像度はルーブリックの一つ）
└─ AI⑤⑥: 未実装（人が課題特定・改善策を検討）

【ルーブリック】
AI③用:
  - needs_coverage（網羅性）
  - evidence_quality（根拠の質）
  - resolution（解像度）

AI④用:
  - strategy_coherence（方針の一貫性）
  - needs_fulfillment（ニーズ充足度）
  - resolution（解像度）
```

#### Phase 2: 改善AI導入版（W4-6）

```
【実装範囲】
├─ AI⑤⑥: 課題特定・改善策AIを実装
├─ 解像度ルーブリックを細分化（問題/状況、ゴール/制約）
└─ 評価精度の検証（人評価との比較）

【発動条件】
AI⑤: AI③の総合評価が△または×の場合
AI⑥: AI④の総合評価が△または×の場合
```

#### Phase 3: 最適化版（W7-9）

```
【実装範囲】
├─ 改善策の自動適用検討（プロンプト修正等）
├─ 過去事例・ナレッジの動的活用
└─ パターン分析・傾向把握
```

### 評価の段階的アプローチ

**課題認識**: 自動評価AIの精度が低い段階では、その評価結果でニーズ推定AI・ソリューション提案AIの精度を正確に測定できない

```
┌─────────────────────────────────────────────────────────────────────┐
│                    評価の段階的アプローチ（アジャイル型）            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【Step 1】初回シナリオで動作確認（W3）                              │
│  ├─ 目的：AIの出力を見せてFB収集                                    │
│  ├─ 内容：1件のシナリオで営業知見者がレビュー                       │
│  └─ 成果：課題把握 + 改善方向性の特定                               │
│                              ↓                                      │
│  【Step 2】改善サイクル + LLM自動評価AI育成（W4-W6）                 │
│  ├─ 目的：精度向上 + LLM自動評価AIを概ね人と一致させる              │
│  ├─ 内容：人の評価データを教師データとして活用                      │
│  └─ 成果：改善効果の確認 + LLM自動評価AIの精度検証                  │
│                              ↓                                      │
│  【Step 3】シナリオ拡張 + 最終評価（W5-W8）                          │
│  ├─ 目的：課題に応じてシナリオ追加、最終精度測定                    │
│  ├─ 内容：LLM自動評価AIが一定精度に達したら残りを自動評価           │
│  └─ 成果：全体の精度把握、改善効果の測定                            │
│                                                                     │
│  ※W6までにLLM自動評価AIが改善しなければ、人評価中心に切り替え       │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 各AIの精度測定

| AI | 精度指標 | 測定方法 | 目標値 |
|----|----------|----------|--------|
| **AI① ニーズ推定** | ニーズ抽出精度 | 正解ニーズとの一致率（人評価） | ◯率70%以上 |
| **AI① ニーズ推定** | 根拠の質 | 根拠が妥当で具体的か（人評価） | ◯率70%以上 |
| **AI② 提案方針策定** | 方針の一貫性 | 経営アジェンダ起点で論理的か（人評価） | ◯率70%以上 |
| **AI② 提案方針策定** | ニーズ充足度 | 全ニーズに対応した方針か（人評価） | ◯率70%以上 |
| **AI② 提案方針策定** | 実行可能性 | ネクストアクションが具体的か（人評価） | ◯率70%以上 |
| **AI③ ニーズ推定評価** | 人との一致 | 概ね人と同じ評価ができるか | 概ね一致 |
| **AI④ 提案方針評価** | 人との一致 | 概ね人と同じ評価ができるか | 概ね一致 |
| **AI⑤ ニーズ改善** | 改善策の有用性 | 提案された改善策が実行可能か（人評価） | - |
| **AI⑥ 提案方針改善** | 改善策の有用性 | 提案された改善策が実行可能か（人評価） | - |

---

## 6.3 評価基準（ルーブリック）【仮版】

> **注**: 本ルーブリックはPoC開始時の仮版です。Phase 1の人評価を通じて精緻化していきます。

### 5段階評価と◯△×判定の対応

| 5段階 | ◯△× | 意味 | 精度計算での扱い |
|-------|------|------|------------------|
| 5, 4 | ◯ | 実用レベル（そのまま使える/軽微な修正で使える） | 合格 |
| 3 | △ | 条件付き（修正すれば使える） | 条件付き合格 |
| 2, 1 | × | 不合格（使えない） | 不合格 |

**精度目標**: ◯率70%以上

### AI① ニーズ推定AI 評価基準

| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 明示的ニーズ・潜在ニーズを漏れなく抽出、優先度付けも適切 |
| 4 | ◯ | 良好 | 主要なニーズを正確に抽出、軽微な漏れ/優先度ズレは許容範囲 |
| 3 | △ | 条件付き | 核心的ニーズは抽出できているが、一部漏れや誤解があり補足が必要 |
| 2 | × | 要改善 | ニーズ抽出が不十分、重要なニーズの見落としがある |
| 1 | × | 不合格 | ニーズを正しく理解できていない、的外れな抽出 |

**評価観点**:
- ニーズの網羅性（明示・潜在両方）
- ニーズの正確性（顧客の意図との一致）
- 優先度の妥当性

**◯△×判定の具体例**:
| 判定 | 具体例 |
|------|--------|
| ◯ | 「資金調達」「事業拡大」「後継者問題」の3ニーズを正確に抽出 |
| △ | 主要ニーズは抽出したが「海外展開意向」という潜在ニーズを見落とし |
| × | 「資金繰り改善」と言われて「コスト削減」と誤解、的外れな方向 |

### AI② 提案方針策定AI 評価基準

> **重要**: 商品起点ではなく、ニーズ・経営アジェンダ起点の提案方針を評価

**方針の一貫性（strategy_coherence）**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 経営アジェンダを起点に一貫したストーリー、Phase設計が論理的 |
| 4 | ◯ | 良好 | 顧客課題起点で論理的、軽微な補足で完成度が上がる |
| 3 | △ | 条件付き | 方向性は妥当だが、ストーリーに一部飛躍がある |
| 2 | × | 要改善 | 商品ありきの提案になっている、論理の一貫性が弱い |
| 1 | × | 不合格 | 経営アジェンダと無関係な提案、ストーリーが破綻 |

**◯△×判定の具体例（方針の一貫性）**:
| 判定 | 具体例 |
|------|--------|
| ◯ | 「コスト改革」を入口に、Phase 1で信頼構築→Phase 2-3で本丸課題に展開する一貫した戦略 |
| △ | 個別ニーズへの対応は適切だが、全体を貫くストーリーが弱い |
| × | 経営アジェンダを無視して「当社の強み商材」を押し付ける提案 |

**ニーズ充足度（needs_fulfillment）**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | 全ニーズに対応した提案方針、優先順位も適切 |
| 4 | ◯ | 良好 | 主要ニーズをカバー、一部は後続フェーズで対応予定と明示 |
| 3 | △ | 条件付き | 核心的ニーズには対応、一部見落としがあるが補足可能 |
| 2 | × | 要改善 | 重要なニーズへの対応が欠落 |
| 1 | × | 不合格 | ニーズと提案方針が合致していない |

**解像度（resolution）**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | ゴール・制約が明確、それに基づいた具体的な提案 |
| 4 | ◯ | 良好 | 概ね把握、不足部分は「確認すべき事項」として明示 |
| 3 | △ | 条件付き | 解像度が低いまま提案、情報収集提案はある |
| 2 | × | 要改善 | 解像度の低さを認識せず具体提案に踏み込んでいる |
| 1 | × | 不合格 | ゴール・制約を全く考慮していない |

**実行可能性（actionability）**:
| スコア | ◯△× | 評価 | 基準 |
|--------|------|------|------|
| 5 | ◯ | 優秀 | ネクストアクションが具体的で即実行可能 |
| 4 | ◯ | 良好 | アクションが明確、軽微な調整で実行可能 |
| 3 | △ | 条件付き | 方向性は分かるが具体性が不足 |
| 2 | × | 要改善 | アクションが抽象的で実行困難 |
| 1 | × | 不合格 | ネクストアクションが欠落または非現実的 |

**評価観点**:
- 経営アジェンダとの整合性（商品起点ではないか）
- 提案ストーリーの論理性
- ニーズへの対応状況
- 情報の解像度と提案の具体度のバランス

### AI③④ LLM自動評価AI 精度検証基準

> **注**: AI③（ニーズ推定評価AI）と AI④（ソリューション推薦評価AI）の両方に適用

**目標**: 概ね人の評価と一致すること

**判定基準**:
| 状態 | 判定 | 対応 |
|------|------|------|
| 概ね人と一致 | 信頼可能 | LLM自動評価のみで可 |
| 一部ズレあり | 条件付き | LLM自動評価 + 人がスポット確認 |
| 大きくズレ | 要改善 | ルーブリック改善、または人評価中心に切り替え |

**W6までに概ね人と一致しなければ、シナリオ拡張を中止し人評価中心に切り替え**

---

## 6.4 評価の3層構造

評価を3つの層に分け、それぞれの役割を明確化します。

```
┌─────────────────────────────────────────────────────────────────────┐
│                        評価の3層構造                                 │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Layer 1: LLM自動品質チェック（毎回・全件・工数ゼロ）                 │
│  ─────────────────────────────────────────────────                  │
│  ・ハルシネーション検出（存在しない商材名など）                      │
│  ・論理整合性チェック（根拠と結論の矛盾）                            │
│  ・業界整合性チェック（IT企業に農業機械など）                        │
│  → 「明らかにダメ」を自動排除                                       │
│                              ↓                                      │
│  Layer 2: LLM比較評価（毎日〜週2-3回・工数極小）                     │
│  ─────────────────────────────────────────────                      │
│  ・ベースライン vs 改善版の相対比較                                  │
│  ・「AとBどちらがマシか」の判定                                      │
│  → 改善方向の確認を高速化                                           │
│                              ↓                                      │
│  Layer 3: 営業知見者実用性評価（週次・絞り込み済みのみ）                    │
│  ─────────────────────────────────────────────                      │
│  ・「使える/使えない」の最終判断                                     │
│  ・具体的な改善フィードバック                                        │
│  → 実務観点での品質保証                                             │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**なぜ3層なのか**:
- Layer 1だけでは「使えるか」の判断ができない
- Layer 3だけでは営業知見者の負荷が大きすぎる（全件は見れない）
- Layer 2を挟むことで、改善サイクルを高速に回せる

---

## 6.5 Layer 1: 自動品質チェック（LLM-as-Judge）

| 項目 | 内容 |
|------|------|
| **目的** | 「明らかにダメな出力」を自動で検出・フィルタリング |
| **タイミング** | 開発中、常時（全件自動実行） |
| **判定者** | LLM（GPT-5.2） + カスタムルーブリック |
| **トレース** | Opik（抽象化レイヤー経由、LangFuse等への切り替え可能） |
| **工数** | ゼロ（完全自動化） |

### チェック項目と判定ロジック

| # | チェック項目 | 判定方法 | NG例 |
|---|-------------|----------|------|
| C1 | **ハルシネーション** | 出力された商材名が商材マスタに存在するか | 「rikyuビジネスローンプレミアム」（存在しない） |
| C2 | **論理整合性** | 根拠からそのニーズが導けるか（LLM判定） | 根拠「売上好調」→ニーズ「資金繰り改善」 |
| C3 | **業界整合性** | その業界の企業に妥当なニーズ/商材か | IT企業に「農業機械リース」を推薦 |
| C4 | **情報カバレッジ** | 入力の重要情報をAIが拾えているか | 「社長70歳」があるのに事業承継に言及なし |

### 評価指標

| 指標 | 定義 | 目標値 | 設定根拠 |
|------|------|--------|----------|
| **自動チェック通過率** | Layer1を全てpassした出力の割合 | **90%以上** | 10件に1件以上NGが出ると改善が追いつかない |
| **ハルシネーション率** | 存在しない商品名等を出力した割合 | **5%以下** | 実務利用において致命的なエラーのため厳格に |
| **論理矛盾率** | 根拠と結論が矛盾している割合 | **10%以下** | 信頼性に直結するため |
| **マッチ率** | 正解商品と提案商品の一致率 | **60%以上** | 改善サイクルの効果確認用 |
| **ナレッジ投入効果** | ナレッジ投入前後での精度差分 | **+15%** | ナレッジの価値を定量化 |

### カスタムルーブリック定義

Layer 1の自動評価では、ドメイン特化の**カスタムルーブリック**を定義し、LLM-as-Judgeで評価を実行する。

#### ルーブリック一覧

| ルーブリック名 | 適用対象 | 評価観点 |
|---------------|---------|---------|
| **needs_coverage** | AI① ニーズ推定 | ニーズの網羅性（顕在・潜在両方） |
| **evidence_quality** | AI① ニーズ推定 | 根拠の妥当性・論理性 |
| **practicality** | AI① AI② 両方 | 実用性・具体性 |
| **solution_fit** | AI② ソリューション伴奏 | ニーズとソリューションの適合度 |
| **reasoning_clarity** | AI② ソリューション伴奏 | 提案理由の明確さ・説得力 |
| **★next_action_quality** | AI② ソリューション伴奏 | ネクストアクションの実行可能性・有用性 |
| **★account_plan_update** | AI② ソリューション伴奏 | アカウントプラン更新提案の有用性・具体性 |
| **★★industry_expertise** | AI① AI② 両方 | 業界知見の反映度（差別化） |
| **★★customer_insight** | AI① AI② 両方 | 顧客理解の深さ（差別化） |
| **★★strategic_approach** | AI② ソリューション伴奏 | 提案戦略の妥当性（差別化） |
| **★★knowledge_application** | AI① AI② 両方 | 蓄積ナレッジの活用度（差別化） |

#### ルーブリック詳細定義

```python
# === カスタムルーブリック定義 ===
CUSTOM_RUBRICS = {
    "needs_coverage": {
        "name": "ニーズ網羅性",
        "description": "顧客の顕在ニーズ・潜在ニーズをどれだけ網羅的に抽出できているか",
        "criteria": """
        5: 顕在ニーズを全て抽出し、潜在ニーズも的確に推定できている
        4: 主要な顕在・潜在ニーズを抽出できているが、軽微な抜けがある
        3: 顕在ニーズの半数程度を抽出、潜在ニーズは一部のみ
        2: 重要な顕在ニーズに抜け漏れがある
        1: ニーズをほとんど抽出できていない、または的外れ
        """,
        "examples": {
            5: "資金調達、事業承継、海外展開、設備投資の4つのニーズを全て抽出し、"
               "社長の年齢から潜在的な相続対策ニーズも推定",
            3: "資金調達と設備投資は抽出したが、面談記録にあった事業承継の話題を見落とし",
            1: "「業績改善」という漠然としたニーズのみで、具体的なニーズを抽出できていない"
        }
    },
    "evidence_quality": {
        "name": "根拠の妥当性",
        "description": "ニーズ推定の根拠が入力情報から論理的に導出されているか",
        "criteria": """
        5: 全てのニーズに具体的な根拠があり、入力情報から論理的に導出されている
        4: 主要なニーズに妥当な根拠があるが、一部推測に依存している
        3: 根拠はあるが、入力情報との紐付けが曖昧な部分がある
        2: 根拠が不十分、または論理の飛躍がある
        1: 根拠が示されていない、または入力情報と矛盾している
        """,
        "examples": {
            5: "「社長65歳、後継者の話題が出た」→ 事業承継ニーズと明確に紐付け",
            3: "「事業承継ニーズあり」とだけ記載し、どの情報から導いたか不明確",
            1: "「資金繰りが厳しい」という根拠から「海外展開ニーズ」を導出（論理の飛躍）"
        }
    },
    "practicality": {
        "name": "実用性・具体性",
        "description": "出力が営業担当者の提案準備として実際に使えるレベルか",
        "criteria": """
        5: そのまま提案準備の起点として使える具体性と実用性がある
        4: 軽微な補足・修正で提案準備に使える
        3: 参考程度にはなるが、そのままでは使えない（追加調査必要）
        2: 抽象的すぎて提案準備には使えない
        1: 的外れで全く使えない
        """,
        "examples": {
            5: "ニーズごとに優先度、根拠、次のアクションまで記載",
            3: "ニーズは列挙されているが、優先度や具体的なアクションが不明",
            1: "「顧客のニーズを深掘りしましょう」という一般論のみ"
        }
    },
    "solution_fit": {
        "name": "ソリューション適合度",
        "description": "推定ニーズに対して適切なソリューションが提案されているか",
        "criteria": """
        5: 全てのニーズに対して最適なソリューションが提案されている
        4: 主要ニーズに適切なソリューションが提案されているが、一部改善の余地あり
        3: ニーズとソリューションの対応は概ね正しいが、一部不整合がある
        2: ニーズとソリューションの対応が不十分
        1: ニーズと無関係なソリューションが提案されている
        """,
        "examples": {
            5: "資金調達ニーズに対し、企業規模・財務状況を踏まえた融資/社債/増資の選択肢を提示",
            3: "資金調達ニーズに融資を提案したが、企業規模に適した社債オプションが漏れ",
            1: "M&Aニーズに対して為替ヘッジ商品を提案（全く的外れ）"
        }
    },
    "reasoning_clarity": {
        "name": "提案理由の明確さ",
        "description": "なぜそのソリューションを推薦するのか、理由が明確に説明されているか",
        "criteria": """
        5: 提案理由が論理的かつ具体的で、顧客を説得できるレベル
        4: 提案理由は明確だが、一部補足があるとより説得力が増す
        3: 提案理由はあるが、抽象的または根拠が弱い
        2: 提案理由が不十分または不明確
        1: 提案理由が示されていない、または矛盾している
        """,
        "examples": {
            5: "「同業界の類似規模企業Aで成約実績あり、財務状況から実現可能」と具体的根拠を提示",
            3: "「融資が適切です」と結論のみで、なぜ融資が最適かの説明なし",
            1: "「M&Aを推奨」としながら、理由が全く記載されていない"
        }
    },
    # ★伴奏AI追加ルーブリック
    "next_action_quality": {
        "name": "ネクストアクション品質",
        "description": "提示されたネクストアクション（経営アジェンダ深掘り・キーパーソン関係深化）の実行可能性と有用性",
        "criteria": """
        5: 具体的で実行可能なアクションが提示され、質問例・アプローチ案も適切
        4: アクションは明確だが、一部補足があるとより実行しやすい
        3: アクションの方向性は正しいが、具体性に欠ける
        2: アクションが抽象的すぎる、または実行可能性が低い
        1: アクションが的外れ、または提示されていない
        """,
        "examples": {
            5: "経営アジェンダ深掘り：「海外展開の具体的な時期・地域を次回面談で確認」"
               "質問例「何年後を想定されていますか」、"
               "キーパーソン関係深化：「常務Aに業界動向レポートを提供」と具体的に提示",
            3: "「海外展開について詳しく聞く」とだけ記載し、質問例やアプローチ方法がない",
            1: "「顧客との関係を深める」という一般論のみ"
        }
    },
    "account_plan_update": {
        "name": "アカウントプラン更新提案有用性",
        "description": "アカウントプラン（経営アジェンダシート・キーパーソンマップ）の更新提案が有用で具体的か",
        "criteria": """
        5: 更新すべき項目が明確で、新情報の追加・既存情報の変更理由も具体的
        4: 更新項目は適切だが、一部理由や詳細が不足
        3: 更新の方向性は正しいが、具体的な項目や理由が曖昧
        2: 更新提案が抽象的すぎる、または有用性が低い
        1: 更新提案が的外れ、または提示されていない
        """,
        "examples": {
            5: "経営アジェンダ：「海外展開の時期」を追加（面談で言及あり）、"
               "キーパーソンマップ：「経理部長」を追加（存在を把握）、常務Aとの関係を「良好」に更新（今回好感触）",
            3: "「アカウントプランを更新すべき」とだけ記載し、具体的な項目や理由がない",
            1: "「特に更新なし」と記載しているが、明らかに新情報が得られている状況"
        }
    },

    # ★★ 知見ベースの評価観点（NTTData PoC2との差別化）★★
    # 関連: 17_differentiation_strategy.md

    "industry_expertise": {
        "name": "業界知見の反映度",
        "description": "業界特有の事情・サイクル・商慣行を考慮しているか",
        "criteria": """
        5: 業界固有の知見を的確に反映（サイクル、商慣行、規制等）
        4: 主要な業界特性を考慮している
        3: 一般的な業界理解に留まる
        2: 業界特性の考慮が不十分
        1: 業界を考慮していない/誤った理解
        """,
        "examples": {
            5: "製造業の設備投資サイクル（5-7年）を踏まえ、"
               "3年後の更新タイミングを見据えた提案",
            3: "製造業に設備投資ニーズを推定したが、"
               "サイクルやタイミングへの言及なし",
            1: "卸売業に農業機械リースを提案（業界ミスマッチ）"
        },
        "knowledge_examples": [
            "製造業の設備投資サイクルは5-7年",
            "卸売業は金利感応度が高い",
            "建設業は公共工事が年度末に集中"
        ]
    },

    "customer_insight": {
        "name": "顧客理解の深さ",
        "description": "発言の本音/建前、経営者タイプ、組織力学を考慮しているか",
        "criteria": """
        5: 発言の裏読み、経営者タイプ別アプローチが的確
        4: 主要な顧客特性を考慮している
        3: 表面的な顧客理解に留まる
        2: 顧客特性の考慮が不十分
        1: 顧客を理解していない提案
        """,
        "examples": {
            5: "「借入増やしたくない」発言を踏まえつつ、"
               "本当の懸念（金利負担）を推測し、リース提案に切り替え",
            3: "発言通り「借入なし」で固定、代替案の検討なし",
            1: "「借入増やしたくない」と言っているのに融資を押し付け"
        },
        "knowledge_examples": [
            "「借入を増やしたくない」≠ 本音とは限らない",
            "創業者は自分で決めたい → 選択肢を提示して選んでもらう",
            "二代目は先代との違いを出したい → 新しい提案を好む"
        ]
    },

    "strategic_approach": {
        "name": "提案戦略の妥当性",
        "description": "段階的アプローチ、りそなの強み活用、成功パターンを踏まえているか",
        "criteria": """
        5: 段階的戦略、強み活用、成功パターン踏襲が完璧
        4: 概ね戦略的だが一部補足が必要
        3: 戦略性はあるが深掘り不足
        2: 戦略が不明確
        1: 戦略なし/場当たり的
        """,
        "examples": {
            5: "Phase1でコスト診断（低リスク）→信頼構築→"
               "Phase2で本丸の事業承継提案という段階戦略",
            3: "事業承継提案は正しいが、段階的アプローチの設計なし",
            1: "初回訪問でいきなりM&Aを提案"
        },
        "knowledge_examples": [
            "Phase1で信頼構築→Phase2-3で本丸という戦略",
            "小さな成功体験から始める",
            "りそなの強み商材を入口に設定"
        ]
    },

    "knowledge_application": {
        "name": "蓄積ナレッジの活用度",
        "description": "過去事例や蓄積した暗黙知を適切に活用しているか",
        "criteria": """
        5: 類似事例・蓄積ナレッジを的確に適用
        4: 主要なナレッジを活用している
        3: ナレッジの活用が部分的
        2: ナレッジの活用が不十分
        1: ナレッジを無視/誤適用
        """,
        "examples": {
            5: "類似業種・規模の成功事例を引用し、"
               "その成功パターンを踏襲した提案",
            3: "事例の存在には触れるが具体的な活用なし",
            1: "明らかに適用すべきルールを無視した提案"
        },
        "knowledge_examples": [
            "社長65歳以上 → 事業承継を必ず考慮",
            "類似事例の成功パターンを踏襲",
            "過去の失敗事例からの学びを反映"
        ]
    }
}
```

#### ルーブリック評価の実装

```python
# === ルーブリック評価実装 ===
from typing import Dict, Any
from pydantic import BaseModel, Field

class RubricScore(BaseModel):
    """個別ルーブリックの評価結果"""
    score: int = Field(ge=1, le=5, description="スコア（1-5）")
    rating: str = Field(description="◯/△/× の判定")
    comment: str = Field(description="評価コメント")
    evidence: str = Field(description="スコアの根拠となる出力部分")

class EvaluationResult(BaseModel):
    """評価結果全体"""
    scores: Dict[str, RubricScore] = Field(description="各ルーブリックのスコア")
    overall_rating: str = Field(description="総合評価 ◯/△/×")
    overall_comment: str = Field(description="総合コメント")


class RubricEvaluator:
    """カスタムルーブリックによる評価"""

    def __init__(self, client: "AzureOpenAIClient", tracer: "TracerInterface"):
        self.client = client
        self.tracer = tracer
        self.rubrics = CUSTOM_RUBRICS

    async def evaluate(
        self,
        output_type: str,  # "needs" or "solution"
        output: dict,
        input_context: dict
    ) -> EvaluationResult:
        """出力をルーブリックに基づいて評価"""

        # 出力タイプに応じたルーブリックを選択
        applicable_rubrics = self._get_applicable_rubrics(output_type)

        with self.tracer.span("rubric_evaluation") as span:
            span.set_input({"output_type": output_type, "rubrics": list(applicable_rubrics.keys())})

            scores = {}
            for rubric_key, rubric in applicable_rubrics.items():
                score = await self._evaluate_single_rubric(
                    rubric_key, rubric, output, input_context
                )
                scores[rubric_key] = score

                # Tracerに評価結果を記録
                self.tracer.log_evaluation(
                    score=score.score / 5.0,  # 0-1に正規化
                    rubric_name=rubric_key,
                    rating=score.rating,
                    metadata={"comment": score.comment}
                )

            # 総合評価を算出
            overall = self._calculate_overall(scores)

            span.set_output({
                "scores": {k: v.model_dump() for k, v in scores.items()},
                "overall_rating": overall["rating"]
            })

            return EvaluationResult(
                scores=scores,
                overall_rating=overall["rating"],
                overall_comment=overall["comment"]
            )

    async def _evaluate_single_rubric(
        self,
        rubric_key: str,
        rubric: dict,
        output: dict,
        input_context: dict
    ) -> RubricScore:
        """単一ルーブリックでの評価"""

        system_prompt = f"""あなたは{rubric['name']}を評価する評価者です。

以下の評価基準に基づいて、出力を1-5のスコアで評価してください。

【評価基準】
{rubric['criteria']}

【評価例】
スコア5の例: {rubric['examples'][5]}
スコア3の例: {rubric['examples'][3]}
スコア1の例: {rubric['examples'][1]}

必ず以下の形式で回答してください:
- score: 1-5の整数
- rating: ◯（4-5）、△（3）、×（1-2）
- comment: 評価理由（50字以内）
- evidence: スコアの根拠となる出力部分を引用
"""

        user_prompt = f"""【入力コンテキスト】
{input_context}

【評価対象の出力】
{output}

上記の出力を「{rubric['name']}」の観点で評価してください。"""

        result = self.client.structured_output(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_model=RubricScore
        )

        return result

    def _get_applicable_rubrics(self, output_type: str) -> Dict[str, dict]:
        """出力タイプに応じたルーブリックを取得"""
        if output_type == "needs":
            return {
                k: v for k, v in self.rubrics.items()
                if k in ["needs_coverage", "evidence_quality", "practicality"]
            }
        elif output_type == "solution":
            # ★伴奏AI対応: ネクストアクション・アカウントプラン更新提案の評価追加
            return {
                k: v for k, v in self.rubrics.items()
                if k in ["solution_fit", "reasoning_clarity", "practicality",
                        "next_action_quality", "account_plan_update"]
            }
        else:
            raise ValueError(f"Unknown output type: {output_type}")

    def _calculate_overall(self, scores: Dict[str, RubricScore]) -> dict:
        """総合評価を算出"""
        avg_score = sum(s.score for s in scores.values()) / len(scores)

        if avg_score >= 4.0:
            rating = "◯"
            comment = "実用レベル：提案準備の起点として使用可能"
        elif avg_score >= 3.0:
            rating = "△"
            comment = "条件付き：補足・修正が必要だが参考になる"
        else:
            rating = "×"
            comment = "要改善：そのままでは使用不可"

        return {"rating": rating, "comment": comment}
```

#### 原因分析・改善策探索機能

評価LLMは単なるスコア付けだけでなく、**原因分析**と**改善策の探索**も行います。

```python
class RootCauseAnalysis(BaseModel):
    """原因分析結果"""
    # 表層的原因
    surface_causes: list[str] = Field(description="表層的な原因（データ不足、プロンプト不備等）")

    # 本質的原因
    fundamental_causes: list[str] = Field(description="本質的な原因")

    # 改善策
    immediate_fixes: list[str] = Field(description="即効性のある改善策")
    structural_improvements: list[str] = Field(description="構造的な改善策")
    future_considerations: list[str] = Field(description="将来的な課題・検討事項")


class EvaluationResultWithAnalysis(BaseModel):
    """原因分析付き評価結果"""
    scores: Dict[str, RubricScore]
    overall_rating: str
    overall_comment: str

    # 成功/失敗の分析
    success_factors: list[str] = Field(description="成功要因（高スコアの場合）")
    root_cause_analysis: RootCauseAnalysis = Field(description="原因分析（低スコアの場合）")
```

**原因分析の観点**:

| カテゴリ | 分析観点 | 例 |
|----------|----------|-----|
| **表層的原因** | データ・プロンプトレベルの問題 | 入力情報不足、プロンプト指示漏れ、商材情報未整備 |
| **本質的原因** | 構造的・知識レベルの問題 | 業界文脈の理解不足、暗黙知の言語化不足、複合判断ロジック欠如、時間軸考慮不足 |
| **成功要因** | なぜうまくいったか | 有効に活用された入力情報、効いているナレッジ・ルール |

**改善策の分類**:

| 分類 | 内容 | 例 |
|------|------|-----|
| **即効** | プロンプト・ナレッジの軽微な修正 | 「顧客発言の裏にある懸念を推測せよ」をプロンプトに追加 |
| **構造的** | システム設計・データ構造の改善 | 財務指標と商材の相性ルールをナレッジに追加、追加シナリオでの学習 |
| **将来的** | PoC範囲外だが認識すべき課題 | リアルタイム外部情報（市況等）の必要性、人との協働が必要なケース |

```
【原因分析の出力例】

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
シナリオ: 製造業の設備投資（L2・失敗ケース）
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

■ 評価結果: NG（スコア 2/5）

■ 成功していた点
  ・設備投資ニーズ自体は正しく抽出できた
  ・工場新設計画の情報を適切に拾えていた

■ 表層的原因
  ・推薦商材が顧客の財務状況と不整合
  ・「借入を増やしたくない」発言を考慮できていない

■ 本質的原因
  ・顧客発言の「本音」と「建前」の区別ができていない
    → 社長の発言は表向きで、本当の懸念は別にある可能性
  ・財務バランスを考慮した複合判断ロジックが不足
    → 自己資本比率35%という情報を商材選定に活かせていない
  ・業界特有の設備投資サイクル（製造業は5-7年）の知識不足
    → 「古い機械を入れ替えたい」のタイミング感が掴めていない

■ 改善策
  【即効】プロンプトに「顧客発言の裏にある懸念を推測せよ」を追加
  【即効】「借入増やしたくない」→ 借入以外の選択肢優先を指示
  【構造】財務指標と商材の相性ルールをナレッジに追加
        （例: 自己資本比率が低い場合はシンジケートローン等で分散）
  【構造】類似ケースのシナリオを追加して学習
  【将来】業界別の設備投資サイクル情報をRAGで参照可能に
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

#### トレースツールとの連携

評価結果は **Opik**（抽象化レイヤー経由）に自動記録され、以下の分析が可能:

```
┌─────────────────────────────────────────────────────────────────────┐
│                  Opikダッシュボードでの可視化                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【評価スコア推移】                                                 │
│  ├─ ルーブリック別のスコア推移（時系列）                           │
│  ├─ 改善前後のスコア比較                                           │
│  └─ プロンプトバージョン別の精度比較                               │
│                                                                     │
│  【弱点分析】                                                       │
│  ├─ スコアが低いルーブリックの特定                                 │
│  ├─ ×判定が多いケースの傾向分析                                    │
│  └─ 改善提案の自動生成（低評価時）                                 │
│                                                                     │
│  【ツール切り替え】                                                 │
│  ├─ 環境変数 TRACER_TYPE=opik | langfuse | noop で切り替え         │
│  ├─ 抽象化レイヤーにより、コード変更なしで移行可能                 │
│  └─ テスト時は NoopTracer で高速実行                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 6.6 Layer 2: LLM比較評価（Pairwise Comparison）

| 項目 | 内容 |
|------|------|
| **目的** | 改善の方向性を素早く確認（絶対評価より相対評価が容易） |
| **タイミング** | 改善サイクル毎（**毎日〜週2-3回**可能） |
| **判定者** | LLM（GPT-5.2） |
| **工数** | 極めて低（完全自動化、結果確認のみ） |

**なぜ相対評価か**:
- 「この出力は80点」という絶対評価は難しい
- 「AとBどちらがマシか」の相対評価は判断しやすい
- 改善の方向性が正しいかを素早く確認できる

### 評価指標

| 指標 | 定義 | 用途 |
|------|------|------|
| **勝率** | 改善版が勝った割合（50件中何件勝ったか） | 改善効果の確認 |
| **観点別勝率** | 網羅性/優先度/根拠別の勝率 | 弱点の特定 |
| **理由の傾向** | LLMが挙げた理由のパターン分析 | 次の改善方針決定 |

### LLM-as-Judgeの限界

```
⚠️ LLM-as-Judgeの限界

1. LLM自身のバイアス
   - 自分（同じLLM）の出力を好む傾向がある
   - 長い出力を「より詳細で良い」と評価しがち

2. ドメイン知識の限界
   - 銀行業界特有の暗黙知は判断できない
   - 「この業界ではこの商材は売れない」等の現場感覚

3. 位置付けの明確化
   - Layer 2は「傾向の把握」「改善方向の確認」用
   - 最終判断はLayer 3の営業知見者評価で行う
```

---

## 6.7 Layer 3: 営業知見者実用性評価

| 項目 | 内容 |
|------|------|
| **目的** | 「実務で使えるか」の最終判断、改善のための具体的フィードバック |
| **タイミング** | 週次レビュー会（毎週60分）または隔週 |
| **判定者** | 営業知見者（ソリビ担当者）2-3名 |
| **工数** | 営業知見者: 週1時間 + 事前確認30分（**Layer 1/2で絞り込み済みのため軽量**） |

### 営業知見者評価シート

```
Q1. この出力を提案準備の起点として使えますか？
    [ ] 5: そのまま使える
    [ ] 4: 少し修正すれば使える
    [ ] 3: 参考程度にはなる
    [ ] 2: あまり役に立たない
    [ ] 1: 全く使えない

Q2. 抜けている重要なニーズは？（自由記述）
Q3. 的外れなニーズは？（自由記述）
Q4. こう直せば使える、というポイントは？（自由記述）
```

### 評価指標

| 指標 | 定義 | 目標値 | 設定根拠 |
|------|------|--------|----------|
| **実用性スコア** | Q1の平均値（1-5点） | **3.5以上** | 「参考になる」と「少し修正すれば使える」の中間 |
| **そのまま使える率** | Q1で4-5の割合 | **50%以上** | 半数以上がそのまま or 少修正で使えるレベル |
| **参考になる率** | Q1で3以上の割合 | **80%以上** | 大多数が最低限「参考にはなる」レベル |
| **重大な抜け漏れ率** | Q2で重要な抜けを指摘された割合 | **20%以下** | 5件に1件以上の重大な抜けは許容できない |

---

## 6.8 評価指標サマリ

| Layer | 指標 | 目標値 | 測定タイミング | 設定根拠 |
|-------|------|--------|---------------|----------|
| **L1** | 自動チェック通過率 | 90%以上 | 毎回 | 改善サイクルを回すための最低ライン |
| **L1** | ハルシネーション率 | 5%以下 | 毎回 | 実務利用で致命的なエラー |
| **L1** | 論理矛盾率 | 10%以下 | 毎回 | 信頼性に直結 |
| **L2** | 改善版勝率 | 60%以上 | 改善サイクル毎 | 改善が正しい方向か確認 |
| **L3** | 実用性スコア | 3.5以上 | 週次 | 「参考になる」以上が平均 |
| **L3** | そのまま使える率 | 50%以上 | 週次 | 半数が直接活用可能 |
| **L3** | 参考になる率 | 80%以上 | 週次 | 大多数が最低限有用 |
| **L3** | 重大な抜け漏れ率 | 20%以下 | 週次 | 5件に1件以上は許容できない |
| **L1** | ★ネクストアクション品質 | 70%以上 | 毎回 | 伴奏AIの核心機能 |
| **L1** | ★AP更新提案有用性 | 60%以上 | 毎回 | アカウントプラン連携の効果測定 |

---

## 6.9 トレース活用評価（障害点特定・改善示唆）

> **参照**: [エージェントアルゴリズム設計](13_agent_algorithm_design.md) Section 6.3

### なぜトレースが評価に必要か

```
┌─────────────────────────────────────────────────────────────────────┐
│                   トレースなし vs トレースあり                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【トレースなし】最終出力のみ評価                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 評価結果: スコア 2/5（ニーズ抽出が不十分）                    │   │
│  │ 改善示唆: 「ニーズをもっと網羅的に抽出してください」          │   │
│  │           ↑ 曖昧で、何をどう直せばいいか不明確                │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  【トレースあり】推論過程も分析                                       │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 障害点分析:                                                   │   │
│  │   ・フェーズ: 入力解釈（input_interpretation）                │   │
│  │   ・問題種別: 情報の見落とし（information_oversight）         │   │
│  │   ・根拠: トレースに「後継者の話題」への言及なし              │   │
│  │   ・根本原因: 面談記録の「最後の雑談」を重要視していない      │   │
│  │                                                               │   │
│  │ 改善示唆:                                                     │   │
│  │   ・対象フェーズ: input_interpretation                        │   │
│  │   ・アクション: 面談記録全体（雑談含む）を重要情報源として     │   │
│  │               分析するようプロンプトに明記                    │   │
│  │   ・期待効果: 潜在ニーズの抽出率向上                          │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 障害点の分類（issue_type）

| 種別 | 説明 | 改善アプローチ |
|------|------|---------------|
| **information_oversight** | 入力情報の見落とし | プロンプトで注目ポイントを明示 |
| **reasoning_error** | 推論ロジックの誤り | Few-shot例の追加、推論ガイダンス |
| **judgment_criteria** | 判断基準の問題 | 基準の明確化、ルーブリック調整 |
| **context_misunderstanding** | 文脈の誤解 | 背景情報の充実、文脈説明の強化 |
| **knowledge_gap** | 知識の不足 | ナレッジDB強化、RAG検討 |

### 改善示唆の具体化

```yaml
# 改善示唆の出力例
improvement_suggestions:
  - target_phase: "input_interpretation"
    action: "面談記録の「最後の雑談」も重要情報として分析対象に含める"
    action_type: "prompt_enhancement"
    expected_effect: "潜在ニーズ（事業承継等）の抽出率向上"
    priority: "高"
    implementation_hint: |
      プロンプトに追加:
      「面談記録の全セクション（雑談・世間話を含む）を分析してください。
       特に、直接的なビジネス話題以外の発言に潜在ニーズが隠れている
       ことが多いです。」

  - target_phase: "priority_assessment"
    action: "優先度判定時に「社長の年齢」を重要ファクターとして考慮"
    action_type: "reasoning_guidance"
    expected_effect: "事業承継ニーズの優先度が適切に評価される"
    priority: "中"
    implementation_hint: |
      判定ガイダンスに追加:
      「社長の年齢が60歳以上の場合、事業承継関連ニーズの優先度を
       1段階上げて検討してください。」
```

---

## 6.10 ナレッジ投入効果の評価 ★新規

> **関連**: [ナレッジ設計](14_knowledge_design.md)

### なぜナレッジ効果を測定するのか

```
┌─────────────────────────────────────────────────────────────────────┐
│                   ナレッジ評価の目的                                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【本PoCの問い】                                                     │
│  「どのナレッジがどれだけ精度向上に寄与するか？」                    │
│                                                                     │
│  【評価で明らかにすること】                                         │
│  ├─ どの種類のナレッジが効果的か（投入順序の決定）                  │
│  ├─ ナレッジの言語化方法は適切か（プロンプトへの組み込み方）        │
│  └─ ナレッジ蓄積の運用コストは妥当か（費用対効果）                  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### ナレッジ種類別の効果測定

| ナレッジ種類 | 評価観点 | 測定方法 | 期待効果 |
|-------------|----------|----------|----------|
| **顧客ニーズナレッジ** | 発言解釈の精度 | 投入前後の比較 | +15%以上 |
| **商品ナレッジ** | 商品選定の妥当性 | 投入前後の比較 | +20%以上 |
| **ソリューションナレッジ** | 事例活用度 | 類似事例の引用率 | 70%以上 |
| **コミュニケーションナレッジ** | アクション品質 | ネクストアクション評価 | +10%以上 |

### 評価指標（ナレッジ関連）

| 指標 | 定義 | 目標値 | 測定タイミング |
|------|------|--------|---------------|
| **ナレッジ投入効果** | ナレッジ投入前後での精度差分 | **+15%以上** | ナレッジ追加時 |
| **暗黙知活用率** | 暗黙知を正しく適用できた割合 | **60%以上** | 毎回 |
| **ナレッジ種類別効果** | 種類別の精度向上幅 | 計測のみ | 月次 |
| **ナレッジ言語化品質** | 言語化されたナレッジの有用性 | **4.0/5.0以上** | ナレッジ作成時 |

### ナレッジ評価の実施方法

```
┌─────────────────────────────────────────────────────────────────────┐
│                   ナレッジ評価のA/Bテスト                             │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  【条件A】ベースライン（ナレッジなし）                               │
│  ├─ 入力: 企業情報 + 面談記録 + 経営アジェンダ + キーパーソンマップ │
│  └─ 出力: ニーズ推定 + ソリューション推薦                           │
│                              ↓                                      │
│  【条件B】ナレッジあり                                               │
│  ├─ 入力: 上記 + 暗黙知ナレッジ（プロンプトに組み込み）             │
│  └─ 出力: ニーズ推定 + ソリューション推薦                           │
│                              ↓                                      │
│  【比較評価】                                                        │
│  ├─ 同一シナリオで条件A/Bの出力を比較                               │
│  ├─ 営業知見者による「どちらがマシか」判定                          │
│  └─ 勝率・改善幅を定量化                                            │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### ナレッジ蓄積サイクルの評価

```
【蓄積サイクル評価のポイント】

1. 抽出の効率性
   - FB1件あたりの抽出ナレッジ数
   - 目標: 1件から1-2個のナレッジを抽出

2. 言語化の品質
   - 営業知見者による「この記述で意図が伝わるか」評価
   - 目標: 4.0/5.0以上

3. 適用の効果
   - 蓄積したナレッジが精度向上に寄与したか
   - 目標: 投入後に精度+10%以上

4. 運用の持続性
   - ナレッジ蓄積にかかる工数
   - 目標: FB対応1件あたり15分以内
```

### トレースへの記録

ナレッジ評価結果もOpikに記録し、以下の分析を可能にする:

- ナレッジ種類別の効果推移
- 効果的だったナレッジパターンの特定
- ナレッジ投入タイミングと効果の相関

---

## 6.11 変更履歴

| バージョン | 日付 | 変更内容 |
|------------|------|----------|
| v1.0 | 2026-01-23 | 初版作成 |
| v1.1 | 2026-01-25 | 伴奏AI対応: AI②の入出力更新、ネクストアクション品質・アカウントプラン更新提案有用性の評価基準追加、カスタムルーブリック追加 |
| v1.2 | 2026-01-25 | **4エージェント構成**: 自動評価AIをニーズ推定評価AI（③）とソリューション推薦評価AI（④）に分離、6.2節の構造図・精度測定表を更新 |
| v1.3 | 2026-01-25 | **トレース活用評価**: 評価AIが推論トレースを分析し、障害点特定・具体的改善示唆を行う設計を追加。6.2節の入出力更新、6.9節（トレース活用評価）を新規追加 |
| v1.4 | 2026-01-26 | **ナレッジ評価追加**: ナレッジ投入効果の評価指標、A/Bテスト設計、蓄積サイクル評価を6.10節として新規追加 |
| v1.5 | 2026-01-29 | **知見ベース評価追加**: NTTData PoC2との差別化として、industry_expertise（業界知見）、customer_insight（顧客理解）、strategic_approach（提案戦略）、knowledge_application（ナレッジ活用）の4つの知見ベースルーブリックを追加 |
